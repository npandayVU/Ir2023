{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Evaluating Search Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we leave aside the code we developed so far, and look into the more general issue of how to evaluate and compare different search engines. The ultimate test for any Information Retrieval system is how well it is able to satisfy the information needs of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohen's Kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation will involve the calculation of [Cohen's kappa](https://en.wikipedia.org/wiki/Cohen's_kappa) to quantify the degree to which two human assessors agree or disagree on whether results are considered relevant or not. To calculate Cohen's kappa, we are going to use the [scikit-learn library](http://scikit-learn.org/stable/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --user scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library expects relevance assessments as lists of elements where `1` stands for _relevant_ and `0` stands for _not relevant_, for example like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=[1,0,1,0,1,0,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list means that the first document was assessed to be relevant, the second to be not relevant, the third to be relevant etc.\n",
    "\n",
    "We need two assessments in order to calculate Cohen's kappa, so let's make another exemplary list that only differs on the last element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=[1,0,1,0,1,0,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke the library as follows to calculate the agreement between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value represents high agreement. We can reach maximal agreement if the two assessments are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(a1, a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what happens for a third assessment that differs on three positions with the first one (the three last positions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3=[1,0,1,0,1,1,0,1]\n",
    "\n",
    "cohen_kappa_score(a1, a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a smaller but still positive value, because these two assessments still mostly agree. If we make a further example that differs on 6 of the 8 positions, we get the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4=[1,0,0,1,0,1,0,1]\n",
    "\n",
    "cohen_kappa_score(a1, a4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is now negative, because the two differ on more positions than they agree. The agreement is in fact less than what you would expect to occur just by chance. We get the maximal disagreement if we define a fifth example that disagrees on all positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a5=[0,1,0,1,0,1,0,1]\n",
    "\n",
    "cohen_kappa_score(a1, a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the kappa score cannot be calculated if you have only `1`s or only `0`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a6=[1,1,1,1,1,1,1,1]\n",
    "a7=[1,1,1,1,1,1,1,1]\n",
    "\n",
    "cohen_kappa_score(a6, a7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the case of a highly skewed set (either vast majority of agreements on `1` or vast majority of agreements on `0`), the kappa score can be counter-intuitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1428571428571428"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a8=[1,1,1,1,1,1,0,1]\n",
    "a9=[1,1,1,1,1,1,1,0]\n",
    "\n",
    "cohen_kappa_score(a8, a9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how this function works, we will apply it below for our specific evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Assessments\n",
    "\n",
    "Next, we will define some auxilary code to deal with lists of URLs from search engines and associated relevance assessments. We will encode result lists like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://en.wikipedia.org/wiki/Information_retrieval/',  # 1st result\n",
    "    'http://www.dictionary.com/browse/information',          # 2nd result\n",
    "    'https://nlp.stanford.edu/IR-book/'                      # ...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we represent corresponding assessments, as above, as lists of the same size containing relevance values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_assessment = [1, 0, 1]\n",
    "another_assessment = [0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to nicely display URL lists, with or without related assessments, we define a function called `display_results`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_results(urls, assessment1=None, assessment2=None):\n",
    "    lines = []\n",
    "    lines.append('<table>')\n",
    "    header = '<tr><th>#</th><th>Result URL</th>'\n",
    "    if (assessment1):\n",
    "        header += '<th>Assessment 1</th>'\n",
    "    if (assessment2):\n",
    "        header += '<th>Assessment 2</th>'\n",
    "    header += '</tr>'\n",
    "    lines.append(header)\n",
    "    i = 0\n",
    "    for url in urls:\n",
    "        show_url = url\n",
    "        if (len(url) > 80):\n",
    "            show_url = url[:75] + '...'\n",
    "        line = '<tr><td>{}</td><td><a href=\"{:s}\">{:s}</a></td>'.format(i+1, url, show_url)\n",
    "        if (assessment1):\n",
    "            if (assessment1[i] == 0):\n",
    "                line += '<td><em>Not relevant</em></td>'\n",
    "            else:\n",
    "                line += '<td><strong>Relevant</strong></td>'\n",
    "        if (assessment2):\n",
    "            if (assessment2[i] == 0):\n",
    "                line += '<td><em>Not relevant</em></td>'\n",
    "            else:\n",
    "                line += '<td><strong>Relevant</strong></td>'\n",
    "        line += '</tr>'\n",
    "        lines.append(line)\n",
    "        i = i+1\n",
    "    lines.append('</table>')\n",
    "    display( HTML(''.join(lines)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function to display a list of URLs, optionally together with one or two assessment lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just a list of URLs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>#</th><th>Result URL</th></tr><tr><td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Information_retrieval/\">https://en.wikipedia.org/wiki/Information_retrieval/</a></td></tr><tr><td>2</td><td><a href=\"http://www.dictionary.com/browse/information\">http://www.dictionary.com/browse/information</a></td></tr><tr><td>3</td><td><a href=\"https://nlp.stanford.edu/IR-book/\">https://nlp.stanford.edu/IR-book/</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With one assessment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>#</th><th>Result URL</th><th>Assessment 1</th></tr><tr><td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Information_retrieval/\">https://en.wikipedia.org/wiki/Information_retrieval/</a></td><td><strong>Relevant</strong></td></tr><tr><td>2</td><td><a href=\"http://www.dictionary.com/browse/information\">http://www.dictionary.com/browse/information</a></td><td><em>Not relevant</em></td></tr><tr><td>3</td><td><a href=\"https://nlp.stanford.edu/IR-book/\">https://nlp.stanford.edu/IR-book/</a></td><td><strong>Relevant</strong></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With two assessments:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>#</th><th>Result URL</th><th>Assessment 1</th><th>Assessment 2</th></tr><tr><td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Information_retrieval/\">https://en.wikipedia.org/wiki/Information_retrieval/</a></td><td><strong>Relevant</strong></td><td><em>Not relevant</em></td></tr><tr><td>2</td><td><a href=\"http://www.dictionary.com/browse/information\">http://www.dictionary.com/browse/information</a></td><td><em>Not relevant</em></td><td><em>Not relevant</em></td></tr><tr><td>3</td><td><a href=\"https://nlp.stanford.edu/IR-book/\">https://nlp.stanford.edu/IR-book/</a></td><td><strong>Relevant</strong></td><td><strong>Relevant</strong></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Just a list of URLs:\")\n",
    "display_results(urls)\n",
    "\n",
    "print(\"With one assessment:\")\n",
    "display_results(urls, my_assessment)\n",
    "\n",
    "print(\"With two assessments:\")\n",
    "display_results(urls, my_assessment, another_assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to perform an actual evaluation, which will involve a substantial amount of manual work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** Noël Panday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Think up and formulate a information need (for example in the field of Computer Science or Medicine) for which you think the answer can be found in scientific publications. On page 152 in the book an example of such an information need is shown: \"Information on whether drinking red wine is more effective at reducing the risk of heart attacks than white wine.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Information on whether consuming dark chocolate is healthier than consuming other types of chocolate, or none at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write down specifically what documents have to look like to satisfy your information need. For example if your information need is about finding an overview of different cancer types, you could state that a document would need to list at least ten types of cancer to satisfy your information need (among other criteria). Write this down as a protocol with rules and examples. For example, such a protocol could state that at least three out of five given criteria have to be fulfilled for a document to be considered relevant for the information need, and then specify the criteria. Or your protocol could have the form of a sequence of rules, where each rule lets you either label the document as relevant or not relevant, or proceed with the next rule. Such rules and criteria can, for example, be about the general topic of the paper, the concepts mentioned in it, the covered relations between concepts, the type of publication (research paper, overview paper, etc.), the number of references, the types of contained diagrams, and so on, depending on your specified information need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "At least two different common types of chocolate should be compared; one of them dark.\n",
    "\n",
    "In the case of human trials, physiological changes per study group should be specified, such as hormone levels.\n",
    "\n",
    "Otherwise, the comparison should address the chemical makeup of studied chocolate samples and specify the theoretical physiological benefits they carry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Formulate a keyword query that represents the information need. For the example on page 152 in the book (see above), the example query \"wine AND red AND white AND heart AND attack AND effective\" is given. (You don't need to use connectors like \"AND\", but if you do, make first sure your chosen search engines below actually support them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** chocolate dark milk white effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then submit your query to **two** of the following academic search engines:\n",
    "\n",
    "- [Google Scholar](https://scholar.google.com) (all science disciplines)\n",
    "- [Semantic Scholar](https://www.semanticscholar.org) (all science disciplines)\n",
    "- [PubMed Search](https://www.ncbi.nlm.nih.gov/pubmed) (Life Sciences / biomedicine)\n",
    "\n",
    "The right choice of two from the three search engine depends on the topic of your information need. If your information need is in the Life Sciences and biomedicine, it's probably best to include PubMed Search, but otherwise you should pick Google Scholar and Semantic Scholar.\n",
    "\n",
    "Extract a list of the top 10 URLs of the lists of each of the search engines given the query. To be ensure that your results are reproducible, it is advised to use the private mode of your browser. Try to access the resulting publications. For the publications where that is not possible (because of dead links or because the publication is pay-walled even within the VU network), exclude them from the list and add more publications to the end of your list (that is, append results number 11, then 12, etc. to ensure you have two lists of 10 publications each). In order to deal with paywalls, you should try accessing the articles from the VU network, use\n",
    "[UBVU Off-Campus\n",
    "Access](http://www.ub.vu.nl.vu-nl.idm.oclc.org/nl/faciliteiten/toegang-buiten-de-campus/index.aspx), or try to find the respective documents from alternative sources (Google Scholar, for example, is very good at finding free PDFs of articles). If you get fewer than 10 results for one of the search engines, modify the keyword query above to make it more inclusive, and then redo the steps of this task.\n",
    "\n",
    "Store your two lists of URLs in the form of Python lists as introduced above. Then, use the `display_results` function to nicely display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scholarly in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (1.7.11)\n",
      "Requirement already satisfied: arrow in c:\\programdata\\anaconda3\\lib\\site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from scholarly) (4.12.2)\n",
      "Requirement already satisfied: bibtexparser in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (1.4.1)\n",
      "Requirement already satisfied: deprecated in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (1.2.14)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: free-proxy in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (1.1.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (0.25.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (from scholarly) (1.0.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\programdata\\anaconda3\\lib\\site-packages (from scholarly) (2.31.0)\n",
      "Requirement already satisfied: selenium in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (4.15.2)\n",
      "Requirement already satisfied: sphinx-rtd-theme in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from scholarly) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from arrow->scholarly) (2.8.2)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from arrow->scholarly) (2.8.19.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->scholarly) (2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from bibtexparser->scholarly) (3.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from deprecated->scholarly) (1.16.0)\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from free-proxy->scholarly) (4.9.3)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->scholarly) (4.0.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->scholarly) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from httpx->scholarly) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->scholarly) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->scholarly) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx->scholarly) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->scholarly) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->scholarly) (1.26.18)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->scholarly) (1.7.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from selenium->scholarly) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from selenium->scholarly) (0.11.1)\n",
      "Requirement already satisfied: sphinx<8,>=1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (7.2.6)\n",
      "Requirement already satisfied: docutils<0.19 in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from sphinx-rtd-theme->scholarly) (0.18.1)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from sphinx-rtd-theme->scholarly) (4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.7)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.1.9)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.6)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.17.2)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.13.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (23.2)\n",
      "Requirement already satisfied: colorama>=0.4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (0.4.6)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium->scholarly) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (from trio-websocket~=0.9->selenium->scholarly) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium->scholarly) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.1.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymed in c:\\users\\noël\\appdata\\roaming\\python\\python311\\site-packages (0.8.9)\n",
      "Requirement already satisfied: requests>=2.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymed) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20.0->pymed) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20.0->pymed) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20.0->pymed) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20.0->pymed) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "! pip install scholarly\n",
    "! pip install pymed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "from pymed import PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"chocolate dark milk white effect\"\n",
    "MAX_RESULTS = 10\n",
    "\n",
    "results_google = scholarly.search_pubs(query=QUERY)\n",
    "results_pubmed = PubMed().query(QUERY, max_results=MAX_RESULTS)\n",
    "\n",
    "list_google = [next(results_google) for i in range(MAX_RESULTS)]\n",
    "list_pubmed = list(results_pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>#</th><th>Result URL</th></tr><tr><td>1</td><td><a href=\"https://www.sciencedirect.com/science/article/pii/S019566631630962X\">https://www.sciencedirect.com/science/article/pii/S019566631630962X</a></td></tr><tr><td>2</td><td><a href=\"https://www.sciencedirect.com/science/article/pii/S0260877415003647\">https://www.sciencedirect.com/science/article/pii/S0260877415003647</a></td></tr><tr><td>3</td><td><a href=\"https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2678792\">https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2678792</a></td></tr><tr><td>4</td><td><a href=\"https://www.sciencedirect.com/science/article/pii/S0040603118305793\">https://www.sciencedirect.com/science/article/pii/S0040603118305793</a></td></tr><tr><td>5</td><td><a href=\"https://link.springer.com/article/10.1007/BF02638052\">https://link.springer.com/article/10.1007/BF02638052</a></td></tr><tr><td>6</td><td><a href=\"https://www.sciencedirect.com/science/article/pii/S1756464618305474\">https://www.sciencedirect.com/science/article/pii/S1756464618305474</a></td></tr><tr><td>7</td><td><a href=\"https://www.sciencedirect.com/science/article/pii/S0308814620323086\">https://www.sciencedirect.com/science/article/pii/S0308814620323086</a></td></tr><tr><td>8</td><td><a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1097-0010(199908)79:11%3C1331::AID-JSFA365%3E3.0.CO;2-4\">https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1097-0010(199908)79:1...</a></td></tr><tr><td>9</td><td><a href=\"https://www.jstage.jst.go.jp/article/fstr/6/4/6_4_269/_article/-char/ja/\">https://www.jstage.jst.go.jp/article/fstr/6/4/6_4_269/_article/-char/ja/</a></td></tr><tr><td>10</td><td><a href=\"https://hrcak.srce.hr/clanak/334632\">https://hrcak.srce.hr/clanak/334632</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>#</th><th>Result URL</th></tr><tr><td>1</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/37224109\">https://pubmed.ncbi.nlm.nih.gov/37224109</a></td></tr><tr><td>2</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/36547013\">https://pubmed.ncbi.nlm.nih.gov/36547013</a></td></tr><tr><td>3</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/35278630\">https://pubmed.ncbi.nlm.nih.gov/35278630</a></td></tr><tr><td>4</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/34828800\">https://pubmed.ncbi.nlm.nih.gov/34828800</a></td></tr><tr><td>5</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/33739547\">https://pubmed.ncbi.nlm.nih.gov/33739547</a></td></tr><tr><td>6</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/33332983\">https://pubmed.ncbi.nlm.nih.gov/33332983</a></td></tr><tr><td>7</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/32326000\">https://pubmed.ncbi.nlm.nih.gov/32326000</a></td></tr><tr><td>8</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/31206711\">https://pubmed.ncbi.nlm.nih.gov/31206711</a></td></tr><tr><td>9</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/31029926\">https://pubmed.ncbi.nlm.nih.gov/31029926</a></td></tr><tr><td>10</td><td><a href=\"https://pubmed.ncbi.nlm.nih.gov/30758419\">https://pubmed.ncbi.nlm.nih.gov/30758419</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create two of the lists below, depending on your chosen engines:\n",
    "\n",
    "urls_google = [pub['pub_url'] for pub in list_google]\n",
    "#urls_semantic = ...\n",
    "urls_pubmed = ['https://pubmed.ncbi.nlm.nih.gov/' + pub.toDict()['pubmed_id'].split('\\n')[0] for pub in list_pubmed]\n",
    "\n",
    "# Call display_results here\n",
    "display_results(urls_google)\n",
    "display_results(urls_pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://pubmed.ncbi.nlm.nih.gov/37224109',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/36547013',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/35278630',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/34828800',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/33739547',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/33332983',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/32326000',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/31206711',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/31029926',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/30758419']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Then, find a fellow student who will **independently**\n",
    "assess the results as \"relevant\" or \"not relevant\" using the protocol that you\n",
    "have defined above, and also help (at least) one other student for his/her\n",
    "assessment. Write down their names here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name of the student who assesses my results:** Linyi Rong\n",
    "\n",
    "**Name of the student who I help to assess his/her results:** Linyi Rong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show to the other assessor everything you have written down above for Tasks 1 and 2 (and you might also want to give him/her the PDFs you got for these papers to simplify the process).\n",
    "\n",
    "You as assessors need to stick to the protocol you made in Task 1 and should not discuss with each other, especially when you doubt whether a result is relevant or not. Write down your assessments as lists of relevance values, as introduced above, and make sure they correctly map to the URLs by displaying them together with the `display_results` function.\n",
    "\n",
    "To avoid problems with extreme results, mark in each list at least one paper as 'relevant' and at least one paper as 'not relevant'. That is, if all papers seem relevant, mark the one that seems least relevant 'not relevant', and conversely, if none of the papers seem relevant, mark the one that seems a bit more relevant than the others as 'relevant'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0 = not relevant; 1 = relevant\n",
    "\n",
    "# You only need to create 4 of the following 6 lists, again depending on which search engines you chose.\n",
    "\n",
    "# Assessment 1 is from you:\n",
    "\n",
    "assessment1_google = [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
    "#assessment1_semantic = ...\n",
    "assessment1_pubmed = [1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
    "\n",
    "# Assessment 2 is from your fellow student (don't show him/her your own assessment!):\n",
    "\n",
    "assessment2_google = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
    "#assessment2_semantic = ...\n",
    "assessment2_pubmed = [1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
    "\n",
    "# Call display_results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Compute Cohen's kappa to quantify how much the two assessors agreed. Use the function `cohen_kappa_score` demonstrated above to calculate two times the inter-annotator agreement (once for each of the two search engines), and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa for Google Scholar: 0.4\n",
      "Kappa for PubMed: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Add your code here:\n",
    "\n",
    "kappa_google = cohen_kappa_score(assessment1_google, assessment2_google)\n",
    "#kappa_semantic = ...\n",
    "kappa_pubmed = cohen_kappa_score(assessment1_pubmed, assessment2_pubmed)\n",
    "\n",
    "print(\"Kappa for Google Scholar:\", kappa_google)\n",
    "#print(\"Kappa for Semantic Scholar:\", kappa_semantic)\n",
    "print(\"Kappa for PubMed:\", kappa_pubmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain whether the agreement can be considered high or not, based on the interpretation table on [this Wikipedia page](https://en.wikipedia.org/wiki/Fleiss'_kappa#Interpretation) (this Wikipedia page is about a different type of kappa but the interpretation table can also be used for Cohen's kappa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Agreement on Google Scholar is fair, while that on PubMed is perfect, which can both be considered high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Define a function called `precision_at_n` that calculates Precision@n as described in the lecture slides, which takes as input an assessment list and a value for _n_ and returns the respective Precision@n value. Run this function to calculate Precision@10 (that is, n=10) on all four assessments (two assessors and two search engines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.5\n",
      "0.3\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "# Add your code here:\n",
    "\n",
    "def precision_at_n(assessment_list, n):\n",
    "   return sum(assessment_list[0:n]) / n\n",
    "\n",
    "# Print out Precision@10 for all assessments here.\n",
    "n = 10\n",
    "print(precision_at_n(assessment1_google, n))\n",
    "print(precision_at_n(assessment2_google, n))\n",
    "print(precision_at_n(assessment1_pubmed, n))\n",
    "print(precision_at_n(assessment2_pubmed, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what these specific Precision@10 results tell us (or don't tell us) about the quality of the two search engines for your particular information need. You can also refer to the results of Task 4 if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** [_Write your answer text here_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to the assignment via Canvas as a modified version of this Notebook file (file with `.ipynb` extension) that includes your code and your answers.\n",
    "\n",
    "Before submitting, restart the kernel and re-run the complete code (**Kernel > Restart & Run All**), and then check whether your assignment code still works as expected.\n",
    "\n",
    "Don't forget to add your name, and remember that the assignments have to be done **individually**, and that code sharing or copying are **strictly forbidden** and will be punished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
